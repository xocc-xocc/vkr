# -*- coding: utf-8 -*-
"""inters.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1baQo-98PFm4SOpopp1skmIWuVqIpI8aG
"""

from sklearn import datasets
import xgboost
from sklearn.model_selection import train_test_split
import pandas as pd
from xgboost import XGBClassifier
from xgboost import XGBRegressor
import shap
from sklearn.inspection import PartialDependenceDisplay
import lime
import lime.lime_tabular
import matplotlib.pyplot as plt

class Inter():
    def __init__(self, data, metka, idd, model_type):
      self.data=data
      self.metka=metka
      self.idd=idd
      self.model_type=model_type

    def mod(self):
      global model
      global X_train
      global X
      global X_test
      global f
      X = self.data.drop([self.metka], axis=1)
      y = self.data[self.metka]
      X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)
      if self.model_type == 'R':
        model = XGBRegressor()
      else:
        model = XGBClassifier()
      model.fit(X_train, y_train)
      y_pred = model.predict(X)
      print('Модель обучена')

    def inter_global(self):
      
      explainer = shap.Explainer(model)
      shap_values = explainer(X_train)
      
      print('Синий цвет точки означает, что признак, на основе которого, расчитывается SHAP values имеет низкое значение, красный цвет - признак имеет высокое значение,')
      print('чем больше значение точки отображающей SHAP values, тем более значимым является признак')
      shap.summary_plot(shap_values, X_train, plot_type="dot")
      print('График отображает значимость признаков модели')
      shap.summary_plot(shap_values, X_train, plot_type="bar")

      print('График отображает значимость признаков модели')
      ftrs=self.data.keys()
      ftrs=ftrs.drop([self.metka])
      print(ftrs)
      features = ftrs 
      fig, axs = plt.subplots(len(features), 1, figsize=(5, 35)) # индексы признаков, для которых строятся PDP both-PDP individual-ICE
      #p=partial_dependence(model, X, features=features, percentiles=(0, 1), grid_resolution=2, kind='both') 
      #print(p)
      disp = PartialDependenceDisplay.from_estimator(model, X, features=features, kind='average',centered=True, ax=axs)
      #plt.show()

    def inter_local(self):
      if self.idd == None:
        print('Введите номер объекта')
      else:
        ftrs=self.data.keys()
        ftrs=ftrs.drop([self.metka])
        print('График отображает значимость признаков для объекта №', self.idd)
        explainer = lime.lime_tabular.LimeTabularExplainer(X_train.values, feature_names=X_train.columns.values.tolist(),
                                                  class_names=[self.metka], verbose=True, mode='regression')
        exp = explainer.explain_instance(X_test.values[self.idd], model.predict, num_features=len(ftrs))
        exp.show_in_notebook(show_table=True)